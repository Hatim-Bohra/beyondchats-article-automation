# BeyondChats Article Automation System

> **Production-grade full-stack application** for automated article scraping, AI enhancement, and content management.

[![TypeScript](https://img.shields.io/badge/TypeScript-007ACC?style=flat&logo=typescript&logoColor=white)](https://www.typescriptlang.org/)
[![React](https://img.shields.io/badge/React-20232A?style=flat&logo=react&logoColor=61DAFB)](https://reactjs.org/)
[![NestJS](https://img.shields.io/badge/NestJS-E0234E?style=flat&logo=nestjs&logoColor=white)](https://nestjs.com/)
[![PostgreSQL](https://img.shields.io/badge/PostgreSQL-316192?style=flat&logo=postgresql&logoColor=white)](https://www.postgresql.org/)

**Live Demo**: [Frontend](http://localhost:5173) | [API Docs](http://localhost:3001/api)

---

## ğŸ“‹ Table of Contents

- [Overview](#overview)
- [Architecture](#architecture)
- [Quick Start](#quick-start)
- [How It Works](#how-it-works)
- [Environment Variables](#environment-variables)
- [API Documentation](#api-documentation)
- [Tech Stack](#tech-stack)

---

## ğŸ¯ Overview

This system automates the entire article enhancement workflow:

1. **Scrapes** articles from BeyondChats blog
2. **Searches** Google for relevant external references
3. **Enhances** content using AI (OpenAI GPT-4 / Anthropic Claude)
4. **Displays** original vs enhanced versions in a responsive UI

**Key Features:**
- âœ… Automated web scraping with multiple strategies
- âœ… AI-powered content enhancement with SEO optimization
- âœ… Asynchronous job processing with retry logic
- âœ… Side-by-side article comparison UI
- âœ… Full REST API with Swagger documentation
- âœ… Production-ready error handling and logging

---

## ğŸ—ï¸ Architecture

### System Design

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   React     â”‚â”€â”€â”€â”€â”€â–¶â”‚   NestJS     â”‚â”€â”€â”€â”€â”€â–¶â”‚ PostgreSQL  â”‚
â”‚  Frontend   â”‚      â”‚   Backend    â”‚      â”‚  Database   â”‚
â”‚  (Port 5173)â”‚      â”‚  (Port 3001) â”‚      â”‚             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â”œâ”€â”€â”€â”€â”€â–¶ Redis (Job Queue)
                            â”œâ”€â”€â”€â”€â”€â–¶ OpenAI API (LLM)
                            â”œâ”€â”€â”€â”€â”€â–¶ SerpAPI (Search)
                            â””â”€â”€â”€â”€â”€â–¶ Puppeteer (Scraping)
```

### Data Flow

```
1. User triggers scraping
   â””â”€â–¶ BeyondChats blog scraped (Puppeteer)
       â””â”€â–¶ Articles saved to PostgreSQL

2. User triggers enhancement
   â””â”€â–¶ Job added to BullMQ queue
       â””â”€â–¶ Google Search for references (SerpAPI)
           â””â”€â–¶ Reference content extracted (Cheerio)
               â””â”€â–¶ LLM enhancement (OpenAI/Anthropic)
                   â””â”€â–¶ Enhanced article saved to DB

3. User views in frontend
   â””â”€â–¶ React Query fetches from API
       â””â”€â–¶ Side-by-side comparison displayed
```

### Monorepo Structure

```
beyondchats-article-automation/
â”œâ”€â”€ apps/
â”‚   â”œâ”€â”€ backend/          # NestJS API
â”‚   â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”‚   â”œâ”€â”€ articles/      # CRUD operations
â”‚   â”‚   â”‚   â”œâ”€â”€ scraper/       # Web scraping (Strategy pattern)
â”‚   â”‚   â”‚   â”œâ”€â”€ automation/    # LLM enhancement pipeline
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ google-search/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ content-scraper/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ llm/       # Provider pattern (OpenAI/Anthropic)
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ jobs/      # BullMQ processors
â”‚   â”‚   â”‚   â””â”€â”€ prisma/        # Database service
â”‚   â”‚   â””â”€â”€ prisma/
â”‚   â”‚       â””â”€â”€ schema.prisma  # Database schema
â”‚   â””â”€â”€ frontend/         # React SPA
â”‚       â”œâ”€â”€ src/
â”‚       â”‚   â”œâ”€â”€ components/    # Reusable UI
â”‚       â”‚   â”œâ”€â”€ pages/         # Route pages
â”‚       â”‚   â””â”€â”€ lib/           # API client & hooks
â”‚       â””â”€â”€ tailwind.config.js
â””â”€â”€ docs/                 # Documentation
```

---

## ğŸš€ Quick Start

### Prerequisites

- Node.js 18+
- PostgreSQL 14+
- Redis 7+
- Docker (optional, recommended)

### Installation

```bash
# 1. Clone repository
git clone https://github.com/yourusername/beyondchats-article-automation.git
cd beyondchats-article-automation

# 2. Install dependencies
npm install

# 3. Start PostgreSQL & Redis (Docker)
docker run --name beyondchats-db -e POSTGRES_PASSWORD=password -e POSTGRES_DB=beyondchats -p 5432:5432 -d postgres:16-alpine
docker run --name beyondchats-redis -p 6379:6379 -d redis:7-alpine

# 4. Configure environment
cd apps/backend
cp .env.example .env
# Edit .env with your API keys

# 5. Setup database
npm run db:generate
npm run db:migrate

# 6. Start development servers
cd ../..
npm run dev:backend  # http://localhost:3001
npm run dev:frontend # http://localhost:5173
```

### Verify Installation

```bash
# Check backend health
curl http://localhost:3001

# Check API docs
open http://localhost:3001/api

# Check frontend
open http://localhost:5173
```

---

## ğŸ”§ How It Works

### Phase 1: Web Scraping

**Endpoint**: `POST /api/v1/scraper/scrape-beyondchats`

```typescript
// Strategy Pattern for extensible scraping
interface ScraperStrategy {
  scrape(): Promise<Article[]>;
}

// BeyondChatsStrategy uses Puppeteer for dynamic content
// GenericArticleStrategy uses Cheerio for static pages
```

**Process:**
1. Puppeteer launches headless browser
2. Navigates to BeyondChats blog
3. Detects pagination (last page number)
4. Extracts: title, content, author, date, URL
5. Saves to PostgreSQL with `status: ORIGINAL`

### Phase 2: AI Enhancement

**Endpoint**: `POST /api/v1/automation/enhance-all`

```typescript
// Job Queue with BullMQ for async processing
const job = await queue.add('enhance', { articleId }, {
  attempts: 3,
  backoff: { type: 'exponential', delay: 2000 }
});
```

**7-Step Enhancement Pipeline:**

1. **Fetch Original** - Get article from database
2. **Google Search** - Find top 2 relevant articles (SerpAPI)
3. **Scrape References** - Extract content from search results
4. **Prepare Context** - Combine original + references (max 3000 chars)
5. **LLM Enhancement** - Send to OpenAI/Anthropic with SEO prompt
6. **Parse Response** - Extract enhanced content + references
7. **Save Enhanced** - Update database with `status: ENHANCED`

**LLM Prompt Strategy:**

```
You are an expert SEO content editor. Enhance this article:

GUIDELINES:
1. Preserve original meaning and key points
2. Improve readability and structure
3. Add depth using provided references
4. Optimize for SEO (keywords, headings)
5. Maintain professional tone

ORIGINAL ARTICLE:
{content}

REFERENCE MATERIALS:
{references}

OUTPUT: Enhanced article in markdown
```

### Phase 3: Frontend Display

**Tech**: React 18 + TanStack Query + Tailwind CSS

**Key Components:**

- `ArticleListPage` - Grid view with status filtering
- `ArticleComparison` - Side-by-side original vs enhanced
- `ArticleCard` - Preview with status badge
- React Query hooks for automatic caching & refetching

**State Management:**

```typescript
// TanStack Query for server state
const { data: articles } = useArticles();

// Automatic background refetching
// Optimistic updates
// Loading & error states handled
```

---

## ğŸ” Environment Variables

### Backend (`apps/backend/.env`)

```env
# Database
DATABASE_URL="postgresql://postgres:password@localhost:5432/beyondchats"

# Redis
REDIS_URL="redis://localhost:6379"

# LLM Provider (openai or anthropic)
LLM_PROVIDER="openai"

# OpenAI
OPENAI_API_KEY="sk-..."
OPENAI_MODEL="gpt-4-turbo-preview"

# Anthropic (optional)
ANTHROPIC_API_KEY="sk-ant-..."

# Google Search
SERPAPI_KEY="..."

# Server
PORT=3001
NODE_ENV="development"
```

### Frontend (`apps/frontend/.env`)

```env
VITE_API_URL="http://localhost:3001/api/v1"
```

---

## ğŸ“š API Documentation

### Interactive Swagger Docs

Visit: **http://localhost:3001/api**

### Key Endpoints

#### Articles

```bash
# Get all articles
GET /api/v1/articles?status=ENHANCED

# Get single article
GET /api/v1/articles/:id

# Create article
POST /api/v1/articles

# Update article
PATCH /api/v1/articles/:id

# Delete article
DELETE /api/v1/articles/:id
```

#### Scraper

```bash
# Scrape BeyondChats blog
POST /api/v1/scraper/scrape-beyondchats

# Scrape single URL
POST /api/v1/scraper/scrape-url
Body: { "url": "https://example.com/article" }
```

#### Automation

```bash
# Enhance all ORIGINAL articles
POST /api/v1/automation/enhance-all

# Enhance specific article
POST /api/v1/automation/enhance/:id

# Check job status
GET /api/v1/automation/jobs/:jobId
```

---

## ğŸ› ï¸ Tech Stack

### Backend

| Technology | Purpose |
|------------|---------|
| **NestJS** | Enterprise-grade Node.js framework |
| **Prisma** | Type-safe ORM for PostgreSQL |
| **BullMQ** | Redis-based job queue |
| **Puppeteer** | Headless browser for dynamic scraping |
| **Cheerio** | Fast HTML parsing for static content |
| **SerpAPI** | Google Search API integration |
| **OpenAI** | GPT-4 for content enhancement |
| **Anthropic** | Claude as alternative LLM |

### Frontend

| Technology | Purpose |
|------------|---------|
| **React 18** | UI library with hooks |
| **Vite** | Fast build tool & dev server |
| **TanStack Query** | Server state management |
| **React Router** | Client-side routing |
| **Tailwind CSS** | Utility-first styling |
| **Axios** | HTTP client with interceptors |
| **react-markdown** | Markdown rendering |

### Database & Infrastructure

| Technology | Purpose |
|------------|---------|
| **PostgreSQL** | Primary database |
| **Redis** | Job queue & caching |
| **Docker** | Containerization |
| **TypeScript** | Type safety across stack |

---

## ğŸ“¸ Screenshots

### Article List View
![Article List](./docs/screenshots/article-list.png)
*Grid view with status filtering and responsive design*

### Article Comparison
![Comparison View](./docs/screenshots/comparison.png)
*Side-by-side original vs enhanced content with references*

### Swagger API Documentation
![API Docs](./docs/screenshots/swagger.png)
*Interactive API documentation with try-it-out functionality*

---

## ğŸ¯ Design Decisions

### Why Strategy Pattern for Scraping?

Different websites require different scraping approaches. The Strategy pattern allows:
- Easy addition of new scrapers without modifying existing code
- BeyondChats uses Puppeteer (dynamic content)
- Generic scraper uses Cheerio (faster for static sites)

### Why TanStack Query over Redux?

For server state management:
- âœ… Automatic caching & background refetching
- âœ… Built-in loading & error states
- âœ… Optimistic updates out of the box
- âœ… Less boilerplate than Redux

### Why BullMQ for Job Processing?

LLM enhancement can take 10-30 seconds per article:
- âœ… Non-blocking API responses
- âœ… Retry logic with exponential backoff
- âœ… Progress tracking
- âœ… Horizontal scaling capability

### Why Monorepo?

- âœ… Shared TypeScript types between frontend/backend
- âœ… Single `npm install` for all dependencies
- âœ… Consistent tooling (ESLint, Prettier)
- âœ… Easier code sharing and refactoring

---

## ğŸ§ª Testing

```bash
# Run all tests
npm test

# Backend unit tests
npm run test:backend

# Frontend component tests
npm run test:frontend

# E2E tests
npm run test:e2e
```

---

## ğŸš€ Deployment

### Backend (Railway / Render)

```bash
# Build
npm run build:backend

# Start production
npm run start:backend
```

### Frontend (Vercel)

```bash
# Build
npm run build:frontend

# Preview
npm run preview:frontend
```

### Environment Variables

Set these in your deployment platform:
- `DATABASE_URL` (from Railway PostgreSQL)
- `REDIS_URL` (from Upstash or Railway)
- `OPENAI_API_KEY`
- `SERPAPI_KEY`
- `VITE_API_URL` (frontend only)

---

## ğŸ“– Documentation

- [Architecture Overview](./docs/ARCHITECTURE.md)
- [Phase 1: Web Scraping](./docs/PHASE1.md)
- [Phase 2: LLM Enhancement](./docs/PHASE2.md)
- [Phase 3: React Frontend](./docs/PHASE3.md)
- [Production Checklist](./docs/PRODUCTION_CHECKLIST.md)

---

## ğŸ¤ Contributing

This is a hiring assignment project. For production use:

1. Add comprehensive test coverage
2. Implement rate limiting
3. Add authentication & authorization
4. Set up monitoring (Sentry, LogRocket)
5. Add CI/CD pipeline
6. Implement WebSocket for real-time job updates

---

## ğŸ“ License

MIT License - see [LICENSE](./LICENSE) file for details

---

## ğŸ‘¤ Author

**Your Name**
- GitHub: [@yourusername](https://github.com/yourusername)
- LinkedIn: [Your Profile](https://linkedin.com/in/yourprofile)
- Email: your.email@example.com

---

## ğŸ™ Acknowledgments

- BeyondChats for the assignment
- OpenAI for GPT-4 API
- NestJS & React communities

---

**Built with â¤ï¸ for BeyondChats Hiring Assignment**
